{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEN\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "# If pytorch 0.3.1, update by adding \"soumath\" in the path and run \"conda update pytorch\" in Anaconda\n",
    "#print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CIFAR = h5py.File(\"..\\CIFAR10.hdf5\",\"r\")\n",
    "x_train = np.float32(CIFAR['X_train'][:])\n",
    "x_test = np.float32(CIFAR['X_test'][:])\n",
    "y_train = np.int32(CIFAR['Y_train'][:])\n",
    "y_test = np.int32(CIFAR['Y_test'][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 3, 32, 32), (10000, 3, 32, 32), (50000,), (10000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transform into torch.Tensor\n",
    "x_traints = torch.Tensor(x_train)\n",
    "y_traints = torch.Tensor(y_train)\n",
    "x_testts = torch.Tensor(x_test)\n",
    "y_testts = torch.Tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pack as torch.Dataset\n",
    "trainset = Data.TensorDataset(x_traints, y_traints)\n",
    "testset = Data.TensorDataset(x_testts, y_testts)\n",
    "# Put datasets into Data Loader\n",
    "BatchSize = 100\n",
    "train_loader = Data.DataLoader(dataset=trainset, batch_size=BatchSize, shuffle=True)\n",
    "test_loader = Data.DataLoader(dataset=testset, batch_size=BatchSize, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "# See: https://pytorch.org/docs/stable/torchvision/transforms.html\n",
    "# Also see: https://blog.csdn.net/u014380165/article/details/79167753\n",
    "from torchvision import transforms\n",
    "ds_trans = transforms.Compose([transforms.RandomCrop(32),\n",
    "                              transforms.RandomHorizontalFlip(),\n",
    "                              transforms.RandomVerticalFlip(),\n",
    "                              transforms.RandomRotation(degrees=45),\n",
    "                              transforms.ColorJitter(\n",
    "                                brightness=0.1*torch.randn(1),\n",
    "                                contrast=0.1*torch.randn(1),\n",
    "                                saturation=0.1*torch.randn(1),\n",
    "                                hue=0.1*torch.randn(1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create torch model with structure given in Slides \"Lecture 6\"\n",
    "LongConv = nn.Sequential(nn.Conv2d(in_channels=3,out_channels=64,kernel_size=4,stride=1,padding=2),\n",
    "                         nn.ReLU(inplace=True), # Conv layer 1\n",
    "                         nn.BatchNorm2d(num_features=64),\n",
    "                         nn.Conv2d(64,64,4,padding=2),\n",
    "                         nn.ReLU(inplace=True), # Conv layer 2\n",
    "                         nn.MaxPool2d(kernel_size=2,stride=2), # Max Pooling\n",
    "                         nn.Dropout2d(p=0.25), # Dropout\n",
    "                         nn.Conv2d(64,64,4,padding=2), \n",
    "                         nn.ReLU(inplace=True), # Conv layer 3\n",
    "                         nn.BatchNorm2d(64),\n",
    "                         nn.Conv2d(64,64,4,padding=2),\n",
    "                         nn.ReLU(inplace=True), # Conv layer 4\n",
    "                         nn.MaxPool2d(kernel_size=2,stride=2), # Max Pooling\n",
    "                         nn.Dropout2d(p=0.25), # Dropout\n",
    "                         nn.Conv2d(64,64,4,padding=2), \n",
    "                         nn.ReLU(inplace=True), # Conv layer 5\n",
    "                         nn.BatchNorm2d(64),\n",
    "                         nn.Conv2d(64,64,3),\n",
    "                         nn.ReLU(inplace=True), # Conv layer 6\n",
    "                         nn.Dropout2d(p=0.25), # Dropout\n",
    "                         nn.Conv2d(64,64,3),\n",
    "                         nn.ReLU(inplace=True), # Conv layer 7\n",
    "                         nn.BatchNorm2d(64),\n",
    "                         nn.Conv2d(64,64,3),\n",
    "                         nn.ReLU(inplace=True), # Conv layer 8\n",
    "                         nn.BatchNorm2d(64),\n",
    "                         nn.Dropout2d(p=0.25)) # Dropout\n",
    "Classifier = nn.Sequential(\n",
    "                         nn.Linear(in_features=64*4*4,out_features=500,bias=True),\n",
    "                         #nn.Linear(in_features=500,out_features=500,bias=True),\n",
    "                         nn.Linear(in_features=500,out_features=10,bias=True),\n",
    "                         nn.Softmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a Convolution NN class\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.ConvLayer = LongConv\n",
    "        self.LinearLayer = Classifier\n",
    "        \n",
    "    def forward(self,x):\n",
    "        ConvOut = self.ConvLayer(x)\n",
    "        Out = ConvOut.reshape(ConvOut.shape[0],-1)\n",
    "        ClassOut = self.LinearLayer(Out)\n",
    "        return ClassOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define model\n",
    "model = ConvNet().to(device)\n",
    "\n",
    "# Define Loss Function and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Small Data loader as a local train set\n",
    "x_trainsmallts = torch.Tensor(x_train[:2000, :])\n",
    "y_trainsmallts = torch.Tensor(y_train[:2000])\n",
    "trainsmallset = Data.TensorDataset(x_trainsmallts, y_trainsmallts)\n",
    "smallBatchSize = 10\n",
    "trainsmall_loader = Data.DataLoader(dataset=trainsmallset, batch_size=smallBatchSize, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/10], Step[100/200], Loss 1.929070, Accuracy 48.000000%\n",
      "Total cost time:0:00:32.724475\n",
      "Epoch[1/10], Step[200/200], Loss 1.882686, Accuracy 49.300000%\n",
      "Total cost time:0:01:33.327817\n",
      "Epoch[2/10], Step[100/200], Loss 2.117649, Accuracy 49.766667%\n",
      "Total cost time:0:02:24.424939\n",
      "Epoch[2/10], Step[200/200], Loss 2.063555, Accuracy 50.150000%\n",
      "Total cost time:0:03:11.109134\n",
      "Epoch[3/10], Step[100/200], Loss 1.812820, Accuracy 50.440000%\n",
      "Total cost time:0:03:55.628519\n",
      "Epoch[3/10], Step[200/200], Loss 1.993241, Accuracy 50.500000%\n",
      "Total cost time:0:04:42.173840\n",
      "Epoch[4/10], Step[100/200], Loss 1.994628, Accuracy 50.657143%\n",
      "Total cost time:0:05:12.816984\n",
      "Epoch[4/10], Step[200/200], Loss 2.040266, Accuracy 50.950000%\n",
      "Total cost time:0:05:45.077648\n",
      "Epoch[5/10], Step[100/200], Loss 1.856857, Accuracy 51.166667%\n",
      "Total cost time:0:06:15.663842\n",
      "Epoch[5/10], Step[200/200], Loss 1.701901, Accuracy 51.260000%\n",
      "Total cost time:0:06:44.980433\n",
      "Epoch[6/10], Step[100/200], Loss 2.018041, Accuracy 51.454545%\n",
      "Total cost time:0:07:14.140441\n",
      "Epoch[6/10], Step[200/200], Loss 1.793661, Accuracy 51.300000%\n",
      "Total cost time:0:07:45.037807\n",
      "Epoch[7/10], Step[100/200], Loss 1.892861, Accuracy 51.476923%\n",
      "Total cost time:0:08:15.017620\n",
      "Epoch[7/10], Step[200/200], Loss 2.065107, Accuracy 51.657143%\n",
      "Total cost time:0:08:42.035358\n",
      "Epoch[8/10], Step[100/200], Loss 2.041511, Accuracy 51.740000%\n",
      "Total cost time:0:09:09.012207\n",
      "Epoch[8/10], Step[200/200], Loss 1.899089, Accuracy 51.781250%\n",
      "Total cost time:0:09:36.294239\n",
      "Epoch[9/10], Step[100/200], Loss 1.962469, Accuracy 51.870588%\n",
      "Total cost time:0:10:03.319957\n",
      "Epoch[9/10], Step[200/200], Loss 1.938751, Accuracy 51.916667%\n",
      "Total cost time:0:10:30.330715\n",
      "Epoch[10/10], Step[100/200], Loss 1.655806, Accuracy 51.936842%\n",
      "Total cost time:0:10:57.557891\n",
      "Epoch[10/10], Step[200/200], Loss 1.910473, Accuracy 52.095000%\n",
      "Total cost time:0:11:24.588595\n"
     ]
    }
   ],
   "source": [
    "# Training process\n",
    "start_time = datetime.datetime.now()\n",
    "num_epochs = 10\n",
    "num_steps = len(train_loader)\n",
    "#num_steps = len(trainsmall_loader)\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i,(images,labels) in enumerate(train_loader):\n",
    "    #for i,(images,labels) in enumerate(trainsmall_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device).long()\n",
    "            \n",
    "        # Forward\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (labels == predicted).sum().item()\n",
    "            \n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        if (i+1)%100 == 0:\n",
    "            print(\"Epoch[{}/{}], Step[{}/{}], Loss {:4f}, Accuracy {:4f}%\".format(\n",
    "                epoch+1, num_epochs, i+1, num_steps, loss.item(), correct/total*100))\n",
    "            now_time = datetime.datetime.now()\n",
    "            print(\"Total cost time:{}\".format(now_time-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on test images:52.82%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate with test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct_test = 0\n",
    "    total_test = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device).long()\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss_test = criterion(outputs, labels)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_test += labels.size(0)\n",
    "        correct_test += (labels == predicted).sum().item()\n",
    "    \n",
    "    print(\"Test Accuracy of the model on test images:{}%\".format(correct_test / total_test * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LEN\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:241: UserWarning: Couldn't retrieve source code for container of type ConvNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "torch.save(model,\"ConvModel.ckpt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
